{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from IPython.core.debugger import Tracer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pandas.read_csv(\"featuresToUseAll.csv\", delimiter=',')\n",
    "#dataframe = pandas.read_csv(\"housing.csv\", delim_whitespace=True, header=None)\n",
    "n_features=24\n",
    "n_target=26 # 26:cadence, 27:step length, 28:speed\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:n_features]\n",
    "Y = dataset[:,n_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "mean = numpy.mean(X)\n",
    "std = numpy.std(X)\n",
    "X = (X - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data between train and test\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "kfolds= KFold(n_splits=4,shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom R^2 error\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN creation\n",
    "nNeuronList=[50] \n",
    "epochs=[10,100] # we used [100, 1000, 1500, 3000,5000,10000]\n",
    "r2testCV = numpy.zeros([len(epochs),2])\n",
    "mseTestCV = numpy.zeros([len(epochs),2])\n",
    "\n",
    "noCVscore = numpy.zeros([len(epochs),2])\n",
    "# scoresTrain = numpy.zeros([len(epochs),2])\n",
    "r2CV=[]\n",
    "mseCV=[]\n",
    "noCVscores=[]\n",
    "# for ind,i in enumerate(nNeuronList):\n",
    "\n",
    "for ind,i in enumerate(epochs):\n",
    " r2CV=[] \n",
    " mseCV=[]\n",
    " for train, test in kfolds.split(X,Y):\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(50, input_dim=n_features, kernel_initializer='normal', activation='tanh')) # https://keras.io/activations/\n",
    "    model1.add(Dense(40, input_dim=n_features, kernel_initializer='normal', activation='tanh'))\n",
    "    model1.add(Dense(30, input_dim=n_features, kernel_initializer='normal', activation='tanh'))\n",
    "    model1.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model1.compile(loss='mean_squared_error', optimizer='adam',metrics=['mae','mse',coeff_determination])\n",
    "    model1.fit(X[train], Y[train],batch_size=10, epochs=i,verbose=0)\n",
    "    score = model1.evaluate(X[test], Y[test], verbose=0)\n",
    "    r2CV.append(score[3])\n",
    "    mseCV.append(score[2])\n",
    " # get the mean over buckets   \n",
    " r2testCV[ind,:]=i,numpy.mean(r2CV)\n",
    " mseTestCV[ind,:]=i,numpy.mean(mseCV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluating the same model on the entire data to get the training scores\n",
    "r2train = numpy.zeros([len(epochs),2])# store R2 for training\n",
    "mseTrain = numpy.zeros([len(epochs),2]) # store mse for training data\n",
    "\n",
    "# for ind,i in enumerate(nNeuronList):\n",
    "for ind,i in enumerate(epochs):\n",
    " \n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=n_features, kernel_initializer='normal', activation='tanh')) # https://keras.io/activations/\n",
    "    model.add(Dense(40, input_dim=n_features, kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(30, input_dim=n_features, kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam',metrics=['mae','mse',coeff_determination])\n",
    "    model.fit(Xtrain, Ytrain,batch_size=10, epochs=i,verbose=0)\n",
    "    score = model.evaluate(Xtest, Ytest, verbose=0)\n",
    "    scoreTrain = model.evaluate(Xtrain,Ytrain,verbose=0)\n",
    "    # storage of data\n",
    "    r2train[ind,:]=i,scoreTrain[3]\n",
    "    mseTrain[ind,:]=i,scoreTrain[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train metrics\n",
    "print(\"\\n Train %s: %.2f\" % (model1.metrics_names[1], scoreTrain[1]))\n",
    "print(\"\\n Train %s: %.2f\" % (model1.metrics_names[2], scoreTrain[2]))\n",
    "print(\"\\n Train %s: %.2f\" % (model1.metrics_names[3], scoreTrain[3]))\n",
    "# test metrics\n",
    "print(\"\\n Test %s: %.2f\" % (model1.metrics_names[1], score[1]))\n",
    "print(\"\\n Test %s: %.2f\" % (model1.metrics_names[2], score[2]))\n",
    "print(\"\\n Test %s: %.2f\" % (model1.metrics_names[3], score[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot Ytest Ypred\n",
    "plt.figure()\n",
    "plt.scatter(Ytest, model1.predict(Xtest), alpha=0.4)\n",
    "plt.ylabel('CV mean Ytest prediction')\n",
    "plt.xlabel('Ytest')\n",
    "plt.title('Prperty Prediction')\n",
    "plt.axis([0,1.5,0,1.5])\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.plot(numpy.linspace(0,1.5,100),numpy.linspace(0,1.5,100),'r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Ytrain Ytrain_pred\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.scatter(Ytrain, model1.predict(Xtrain),alpha=0.4)\n",
    "plt.ylabel('Ytrain prediction')\n",
    "plt.xlabel('Ytrain')\n",
    "plt.title('Property Prediction')\n",
    "plt.xlim([0,1.5])\n",
    "plt.ylim([0,1.5])\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.plot(numpy.linspace(0,1.5,100),numpy.linspace(0,1.5,100),'r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot R2\n",
    "import matplotlib\n",
    "fig1=plt.figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "plt.scatter(r2testCV[:,0], r2testCV[:,1],alpha=0.4, label='CV Testing')\n",
    "plt.scatter(r2train[:,0], r2train[:,1],alpha=0.4, label='Training')\n",
    "\n",
    "plt.ylabel(r'$R^2$')\n",
    "plt.xlabel('epochs number')\n",
    "plt.title(r'$R^2$ - Property Prediction')\n",
    "plt.legend()\n",
    "# fig1.savefig('NN_cadence_r2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot MSE\n",
    "fig2=plt.figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "plt.scatter(mseTrain[:,0], mseTrain[:,1],alpha=0.4, label='Training')\n",
    "plt.scatter(mseTestCV[:,0], mseTestCV[:,1],alpha=0.4, label='CV Testing')\n",
    "plt.ylabel(r'MSE')\n",
    "plt.xlabel('Epochs number')\n",
    "plt.title(r'MSE - Property Prediction')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# fig2.savefig('NN_speed_mse.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "data=np.vstack((r2train[:,0],r2train[:,1],r2testCV[:,1],mseTrain[:,1], mseTestCV[:,1]))\n",
    "np.save('NN_property.npy',data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
